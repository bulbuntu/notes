{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary Least Squares\n",
    "--\n",
    "\n",
    "$y=\\left[ {\\begin{array}{c} y_1\\\\y_2\\\\\\vdots\\\\y_n \\end{array}} \\right]$\n",
    "  \n",
    "$X=\\left[ {\\begin{array}{cccc} x_{1,1}&x_{1,2}&\\cdots&x_{1,p}\\\\\n",
    "                               x_{2,1}&x_{2,2}&\\cdots&x_{2,p}\\\\\n",
    "                               \\vdots\\\\\n",
    "                               x_{n,1}&x_{n,2}&\\cdots&x_{n,p} \\end{array}} \\right]$\n",
    "                               \n",
    "$\\beta=\\left[ {\\begin{array}{c} \\beta_1\\\\\\beta_2\\\\\\vdots\\\\\\beta_p \\end{array}} \\right]$\n",
    "  \n",
    "$\\hat{y}=X\\beta$\n",
    "  \n",
    "Least Square Errors are  \n",
    "$\\operatorname {LSE}=\\operatorname Q(\\beta)$  \n",
    "$\\qquad= \\sum_{i=1}^{n}(y_i-\\sum_{j=1}^px_{i,j}\\beta_j)^2$  \n",
    "$\\qquad=\\sum_{i=1}^{n}(y_i-X[i,]\\beta)^2\\qquad$ We are taking $i^{th}$ row from $X_{n,p}$ matrix.  \n",
    "$\\qquad=(y-X\\beta)^T(y-X\\beta)$  \n",
    "\n",
    "To minimize $Q(\\beta)$ make $\\frac{\\delta Q(\\beta)}{\\delta\\beta}=0$  \n",
    "$\\frac{\\delta Q(\\beta)}{\\delta\\beta_j}= \\sum_{i=1}^{n}-2x_{i,j}(y_i-\\sum_{j=1}^px_{i,j}\\beta_j)=0$  \n",
    "$\\qquad=-2X[,j]^T(y-X\\beta)$  \n",
    "$\\left[ {\\begin{array}{c} \\frac{\\delta Q(\\beta)}{\\delta\\beta_1}\\\\\\frac{\\delta Q(\\beta)}{\\delta\\beta_2}\\\\\\vdots\\\\\\frac{\\delta Q(\\beta)}{\\delta\\beta_p}\\end{array}}\\right]$= $-2 \\left[\\begin{array}{c} X[,1]^T\\\\X[,2]^T\\\\\\vdots\\\\X[,p]^T \\end{array}\\right] (y-X\\beta)=0\\qquad$  \n",
    "Note:  \n",
    "$\\quad X[i,]$ implies $i^{th}$ row of Matrix X.  \n",
    "$\\quad X[,j]$ implies $j^{th}$ column of Matrix X.  \n",
    "$X^T(y-X\\beta)=\\left[\\begin{array}{c}0\\\\0\\\\\\vdots\\\\0\\end{array}\\right]$  \n",
    "$X^TX\\beta=X^Ty$  \n",
    "$\\hat\\beta=(X^TX)^{-1}X^Ty$  \n",
    "<div style=\"border:solid\">\n",
    "$\\hat y=X\\hat\\beta$  \n",
    "$\\hat y=X(X^TX)^{-1}X^Ty$</div>\n",
    "--\n",
    "$\\hat y=Hy$  \n",
    "\n",
    "H the hat matrix can be considered as a transformation/projection matrix which transforms a random $R^n$ vector onto the orthonormal space of X or the Columns Space of X.  \n",
    "(We call it the Columns Space in X because by definition, as $X^TX$ had an inverse, meant that $X$ has a *Full Column Rank*)\n",
    "\n",
    "Need to NAIL the understanding of \n",
    "* Rank Vs \n",
    "* Orthonormal Space Dimensions => \n",
    "  1. Is is equal to number of unique eigen values or\n",
    "  2. Is it the sum of all Geometric Multiplicites or\n",
    "  3. Is is the sum of all Algebraic Multiplicites \n",
    "* Algebraic Multiplicity of an eigen value Vs\n",
    "* Geometric Multiplicity of an eigen value Vs \n",
    "* Gram Schmidt Process Vs \n",
    "* Cholesky Vs \n",
    "* QR Decomposition.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
